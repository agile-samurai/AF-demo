resource_types:
  - name: terraform
    type: docker-image
    source:
      repository: ljfranklin/terraform-resource
      tag: 0.12.5
  - name: slack-notification
    type: docker-image
    source:
      repository: cfcommunity/slack-notification-resource
  - name: simple-s3-resource
    type: docker-image
    source:
      repository: 18fgsa/s3-resource-simple

resources:
  - name: slack-notify
    type: slack-notification
    source:
      url: ((slack_webhook))
  - name: terraform
    type: terraform
    source:
      backend_type: s3
      backend_config:
        bucket: ((tf_backend_bucket))
        key: rdso.tfstate
        region: ((bucket_aws_region))
        access_key: ((aws_access_key_id))
        secret_key: ((aws_secret_access_key))
      env:
        AWS_ACCESS_KEY_ID: ((aws_access_key_id))
        AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
  - name: source
    type: git
    source: &repo-source
      uri: ((git_source_url))
      branch: master
      username: ((git_username))
      password: ((git_password))
  - name: hsm-source
    type: git
    source: &repo-source
      uri: ((git_source_url))
      branch: master
      paths:
        - config/**/*
      username: ((git_username))
      password: ((git_password))
  - name: version
    type: semver
    source:
      driver: git
      uri: ((git_source_url))
      initial_version: 0.0.1
      branch: version
      file: version
      username: ((git_username))
      password: ((git_password))
  ################### Resources ECR REPOS ######################
  - name: server-docker-image
    type: docker-image
    source:
      aws_access_key_id: ((aws_access_key_id))
      aws_secret_access_key: ((aws_secret_access_key))
      repository: ((aws_account_id)).dkr.ecr.us-east-1.amazonaws.com/server
  - name: main-ds-service-docker-image
    type: docker-image
    source: #049492283767.dkr.ecr.us-east-1.amazonaws.com
      repository: ((aws_account_id)).dkr.ecr.us-east-1.amazonaws.com/data-science-service
      aws_access_key_id: ((aws_access_key_id))
      aws_secret_access_key: ((aws_secret_access_key))
  - name: client-docker-image
    type: docker-image
    source:
      repository: ((aws_account_id)).dkr.ecr.us-east-1.amazonaws.com/ui
      aws_access_key_id: ((aws_access_key_id))
      aws_secret_access_key: ((aws_secret_access_key))
  - name: models
    type: simple-s3-resource
    source:
      access_key_id: ((aws_access_key_id))
      secret_access_key: ((aws_secret_access_key))
      bucket: ((app_data_bucket))
      path: data/ci/models
      region: ((bucket_aws_region))
      options:
        - "--exclude '*'"
        - "--include '*movies*model*'"
        - "--include '*metrics*'"
  - name: data
    type: simple-s3-resource
    source:
      access_key_id: ((aws_access_key_id))
      secret_access_key: ((aws_secret_access_key))
      bucket: ((app_data_bucket))
      path: data/ci/data
      options:
        - "--exclude '*'"
        - "--include '*.pkl'"
      region: ((bucket_aws_region))
  # - name: data
  #   type: s3
  #   source:
  #     bucket: ((app_data_bucket))
  #     regexp: data/movies_df.pkl
  #     access_key_id: ((aws_access_key_id))
  #     secret_access_key: ((aws_secret_access_key))
  - name: raw_data
    type: simple-s3-resource
    source:
      access_key_id: ((aws_access_key_id))
      secret_access_key: ((aws_secret_access_key))
      bucket: ((app_data_bucket))
      path: /data/ci/raw
      region: ((bucket_aws_region))
  - name: omdb_json
    type: simple-s3-resource
    source:
      access_key_id: ((aws_access_key_id))
      secret_access_key: ((aws_secret_access_key))
      bucket: ugroup-rdso-challenge-data
      path: omdb_json
      region: us-east-1

groups:
  - name: all
    jobs:
    - Deploy HSM - Dev
    - Deploy HSM - Prod
    - Initialize
    - Consolidate Data
    - Build UI
    - Build server and SonarQube
    - Execute server Functional Tests
    - Execute server Contract Tests
    - Execute UI Automated Tests
    - Provision ECR Repositories
    - Push UI
    - Push server Image
    - Push Data Model Image
    - Deploy Services To Dev
    - Deploy Services To Test
    - Deploy Services To Production
    - Execute Data Model Tests
    - Train Models
    - Capture data and push to s3
    - pa11y-accessibility-scan
    - OWASP Prod Security Scan
    #- create lb ss cert
  - name: prepare
    jobs:
    - Deploy HSM - Dev
    - Initialize
  - name: model building
    jobs:
    - Capture data and push to s3
    - Train Models
    #- Push Data Service
  - name: build-and-test
    jobs:
    - Build UI
    - Build server and SonarQube
    - Execute server Functional Tests
    - Execute server Contract Tests
    - Execute UI Automated Tests
    - Execute Data Model Tests
  - name: publish-and-scan
    jobs:
    - Provision ECR Repositories
    - Push UI
    - Push server Image
    - Push Data Model Image
    - Deploy Services To Dev
    - Deploy Services To Test
    - Deploy Services To Production
    - OWASP Prod Security Scan
    - pa11y-accessibility-scan
  - name: destroy
    jobs:
      - terraform-destroy-all-envs
      - terraform-destroy-dev-service
      - terraform-destroy-test-service
      - terraform-destroy-prod-service
      - REMOVE HSM - Prod
      - REMOVE HSM - Test
      - REMOVE HSM - Dev

jobs:
  # TODO: test this
      ###NOW FLY SETPIPELINE WITH SONARQUBE URL
      ####add output from this step
  - name: Initialize
    public: true
    plan:
      - get: source
        trigger: true
      - put: version
        params: {bump: minor}
  - name: Deploy HSM - Dev
    public: true
    serial: true
    plan:
      - get: hsm-source
        #trigger: true
      - task: Deploy HSM
        attempts: 2
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-terraform-aws
          inputs:
              - name: hsm-source
          run:
            path: /bin/bash
            args:
            - -exc
            - |
                yum install bind-utils openssl openssl-devel wget maven -y
                wget https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/EL7/cloudhsm-client-latest.el7.x86_64.rpm && yum install -y ./cloudhsm-client-latest.el7.x86_64.rpm
                wget https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/EL7/cloudhsm-client-jce-latest.el7.x86_64.rpm && yum install -y ./cloudhsm-client-jce-latest.el7.x86_64.rpm
                mvn install:install-file -Dfile=/opt/cloudhsm/java/cloudhsm-2.0.3.jar -DgroupId=com.cavium -DartifactId=cloudhsm -Dversion=2.0.3 -Dpackaging=jar
                cd hsm-source/services/hsmgateway
                mvn clean install -DskipTests
                cp target/hsmgateway-0.0.1-SNAPSHOT.jar ../../../hsm-source/config/hsm-setup/initial-setup/
                cd ../../../
                cd hsm-source/config/hsm-setup/initial-setup

                terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=hsm.tfstate"
                terraform workspace new dev || true
                terraform workspace list
                terraform workspace select dev
                export AWS_DEFAULT_REGION=us-east-1
                export TF_VAR_REGION=us-east-1
                export TF_VAR_hsm_controller=$(dig @resolver1.opendns.com ANY myip.opendns.com +short -4)
                echo $TF_VAR_hsm_controller
                terraform plan -out plan -target=aws_cloudhsm_v2_hsm.cloudhsm_v2_hsm -target=local_file.ec2_key && terraform apply plan
                echo $TF_VAR_hsm_controller
                terraform plan -out plan && terraform apply plan
                echo $TF_VAR_hsm_controller
  - name: Deploy HSM - Prod
    public: true
    serial: true
    plan:
      - get: hsm-source
        #trigger: true
      - task: Deploy HSM
        attempts: 2
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-terraform-aws
          inputs:
            - name: hsm-source
          run:
            path: /bin/bash
            args:
            - -exc
            - |
                yum install bind-utils openssl openssl-devel wget maven -y
                wget https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/EL7/cloudhsm-client-latest.el7.x86_64.rpm && yum install -y ./cloudhsm-client-latest.el7.x86_64.rpm
                wget https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/EL7/cloudhsm-client-jce-latest.el7.x86_64.rpm && yum install -y ./cloudhsm-client-jce-latest.el7.x86_64.rpm
                mvn install:install-file -Dfile=/opt/cloudhsm/java/cloudhsm-2.0.3.jar -DgroupId=com.cavium -DartifactId=cloudhsm -Dversion=2.0.3 -Dpackaging=jar
                cd hsm-source/services/hsmgateway
                mvn clean install -DskipTests
                cp target/hsmgateway-0.0.1-SNAPSHOT.jar ../../../hsm-source/config/hsm-setup/initial-setup/
                cd ../../../
                cd hsm-source/config/hsm-setup/initial-setup
                ls -all

                terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=hsm.tfstate"
                terraform workspace new prod-ir || true
                terraform workspace list
                terraform workspace select prod-ir
                export AWS_DEFAULT_REGION=eu-west-1
                export TF_VAR_REGION=eu-west-1
                TF_VAR_hsm_controller=$(dig @resolver1.opendns.com ANY myip.opendns.com +short -4) terraform plan -out plan -target=aws_cloudhsm_v2_hsm.cloudhsm_v2_hsm -target=local_file.ec2_key && terraform apply plan
                TF_VAR_hsm_controller=$(dig @resolver1.opendns.com ANY myip.opendns.com +short -4) terraform plan -out plan && terraform apply plan
  - name: REMOVE HSM - Prod
    public: true
    serial: true
    plan:
      - get: hsm-source
        trigger: true
      - task: REMOVE HSM - Prod
        attempts: 2
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-terraform-aws
          inputs:
              - name: hsm-source
          run:
            path: /bin/bash
            args:
            - -exc
            - |
                cd hsm-source/config/hsm-setup/initial-setup
                touch key.pem
                terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=hsm.tfstate"
                terraform workspace new prod-ir || true
                terraform workspace list
                terraform workspace select prod-ir
                export AWS_DEFAULT_REGION=eu-west-1
                export TF_VAR_REGION=us-east-1
                TF_VAR_hsm_controller="10.10.10.10" terraform destroy -auto-approve
  - name: REMOVE HSM - Dev
    public: true
    serial: true
    plan:
      - get: hsm-source
        trigger: true
      - task: Destroy HSM Dev
        attempts: 2
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-terraform-aws
          inputs:
              - name: hsm-source
          run:
            path: /bin/bash
            args:
            - -exc
            - |
                cd hsm-source/config/hsm-setup/initial-setup
                touch key.pem
                terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=hsm.tfstate"
                terraform workspace new dev || true
                terraform workspace list
                terraform workspace select dev
                export AWS_DEFAULT_REGION=us-east-1
                export TF_VAR_REGION=us-east-1
                TF_VAR_hsm_controller="10.10.10.10" terraform destroy -auto-approve
  - name: REMOVE HSM - Test
    public: true
    serial: true
    plan:
      - get: hsm-source
        trigger: true
      - task: REMOVE HSM - Test
        attempts: 2
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-terraform-aws
          inputs:
              - name: hsm-source
          run:
            path: /bin/bash
            args:
            - -exc
            - |
                cd hsm-source/config/hsm-setup/initial-setup
                touch key.pem
                terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=hsm.tfstate"
                terraform workspace new test || true
                terraform workspace list
                terraform workspace select test
                export AWS_DEFAULT_REGION=us-west-1
                export TF_VAR_REGION=us-west-1
                TF_VAR_hsm_controller="10.10.10.10" terraform destroy -auto-approve
  - name: terraform-destroy-all-envs
    public: false
    plan:
    - put: terraform
      attempts: 2
      get_params:
        action: destroy
      params:
        env_name: ecr
        terraform_source: hsm-source/config/ecr-setup
        action: destroy
        env:
          TF_VAR_aws_region: ((bucket_aws_region))
          TF_VAR_aws_account_id: ((aws_account_id))
          TF_VAR_bucket_name: ((tf_backend_bucket))
          TF_VAR_business_supervisor_password": "noop"
          TF_VAR_business_user_password: "noop"
          TF_VAR_jwt_secret: "noop"
          TF_VAR_system_user_password: "noop"
  #   - get: source
  #   - put: terraform
  #     get_params:
  #       action: destroy
  #     params:
  #       terraform_source: source/config/service-setup
  #       action:
  #       env_name: dev
  #   - put: terraform
  #     get_params:
  #       action: destroy
  #     params:
  #       terraform_source: source/config/service-setup
  #       action:
  #       env_name: test
  #   - put: terraform
  #     get_params:
  #       action: destroy
  #     params:
  #       terraform_source: source/config/service-setup
  #       action:  destroy
  #       env_name: prod
  - name: terraform-destroy-dev-service
    public: false
    serial: true
    plan:
    - get: source
    - put: terraform
      attempts: 2
      get_params:
        action: destroy
      params:
        terraform_source: source/config/service-setup
        action: destroy
        env_name: dev  #workspace
        env:
          TF_VAR_access_key: ((aws_access_key_id))
          TF_VAR_access_secret: ((aws_secret_access_key))
          TF_VAR_aws_account_id: ((aws_account_id))
          TF_VAR_bucket_name: ((tf_backend_bucket))
          TF_VAR_images_version: "noop"
          TF_VAR_infra_version: "noop"
          TF_VAR_business_supervisor_password": "noop"
          TF_VAR_business_user_password: "noop"
          TF_VAR_jwt_secret: "noop"
          TF_VAR_system_user_password: "noop"
  - name: terraform-destroy-test-service
    public: false
    serial: true
    plan:
    - get: source
    - put: terraform
      attempts: 2
      get_params:
        action: destroy
      params:
        terraform_source: source/config/service-setup
        action: destroy
        env_name: test  #workspace
        env:
          TF_VAR_access_key: ((aws_access_key_id))
          TF_VAR_access_secret: ((aws_secret_access_key))
          TF_VAR_aws_account_id: ((aws_account_id))
          TF_VAR_bucket_name: ((tf_backend_bucket))
          TF_VAR_images_version: "noop"
          TF_VAR_infra_version: "noop"
          TF_VAR_business_supervisor_password": "noop"
          TF_VAR_business_user_password: "noop"
          TF_VAR_jwt_secret: "noop"
          TF_VAR_system_user_password: "noop"
  - name: terraform-destroy-prod-service
    public: false
    serial: true
    plan:
    - get: source
    - put: terraform
      attempts: 2
      get_params:
        action: destroy
      params:
        terraform_source: source/config/service-setup
        action: destroy
        env_name: prod  #workspace
        env:
          TF_VAR_access_key: ((aws_access_key_id))
          TF_VAR_access_secret: ((aws_secret_access_key))
          TF_VAR_aws_account_id: ((aws_account_id))
          TF_VAR_bucket_name: ((tf_backend_bucket))
          TF_VAR_images_version: "noop"
          TF_VAR_infra_version: "noop"
          TF_VAR_business_supervisor_password": "noop"
          TF_VAR_business_user_password: "noop"
          TF_VAR_jwt_secret: "noop"
          TF_VAR_system_user_password: "noop"
  - name: Capture data and push to s3
    public: true
    serial: true
    plan:
      - get: source
        passed: [Initialize]
      - task: Gather Data
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
          AWS_REGION: ((bucket_aws_region))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: carlomazzaferro/concourse-python-minimal
          run:
            path: sh
            args:
            - -ec
            - |
              cd source/services/data-science-service/imdb-scraper
              pip install --quiet -r requirements.txt
              export TESTING=true
              export MAX_TRAINING_FILES=10
              python scraper.py && python parser.py
              cd ../rdso
              apt-get -qq update && apt-get -qq -y install gcc
              # yum -y install epel-release
              # yum -y install python-pip
              pip install --quiet --upgrade pip
              pip install --quiet -r requirements.txt
              python -m nltk.downloader stopwords
              python movies.py
              cd ../../../../
              cp -R source/services/data-science-service/data/ raw_data
              pwd
              ls -all
          inputs:
            - name: source
          outputs:
            - name: raw_data
      - put: raw_data
  - name: Consolidate Data
    public: true
    serial: true
    plan:
      - get: source
      - get: version
        trigger: true
        passed: [Initialize]
      - get: omdb_json
        trigger: true
      - task: Create Pickle File
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
          AWS_DEFAULT_REGION: us-east-1
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: carlomazzaferro/concourse-python-minimal
          run:
            path: sh
            args:
            - -ec
            - |
              mkdir -p source/services/data-science-service/data
              cp -r omdb_json source/services/data-science-service/rdso/
              cd source/services/data-science-service/imdb-scraper
              pip install --quiet -r requirements.txt
              cd ../rdso
              apt-get -qq update && apt-get -qq -y install gcc
              # yum -y install epel-release
              # yum -y install python-pip
              pip install --quiet --upgrade pip
              pip install --quiet -r requirements.txt
              python -m nltk.downloader stopwords
              python movies.py
              cd ../../../../
              cp source/services/data-science-service/data/movies_df.pkl data
              ls -al data
              rm -rf source/services/data-science-service/data/omdb_json
              rm -rf data/data/omdb_json
              ls .
              rm -rf data/omdb_json

              echo "Foo br"
          inputs:
            - name: source
            - name: omdb_json
          outputs:
            - name: data
      - put: data
        params:
          file: data/movies_df.pkl
  - name: Train Models
    public: true
    serial: true
    plan:
      - get: source
      # - get: version
      #   passed: [Initialize]
      - get: data
        trigger: true
        passed: [Consolidate Data]
      - task: Train model
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
          AWS_REGION: ((bucket_aws_region))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: carlomazzaferro/concourse-python-minimal
          run:
            path: sh
            args:
            - -ec
            - |
              mkdir -p source/services/data-science-service/rdso/data/
              mkdir -p source/services/data-science-service/rdso/models/
              ls ./data/data/
              echo "______________________----------____________________"
              cp -R ./data/data/* source/services/data-science-service/rdso/data/
              ls -all source/services/data-science-service/rdso/data/.
              echo "______________________----------____________________"
              cd source/services/data-science-service/rdso
              apt-get -qq update && apt-get -qq -y install gcc
              pip install --quiet --upgrade pip
              pip install --quiet -r requirements.txt
              python -c "import nltk;nltk.download('stopwords')"
              python vectorize.py
              ls -all models/
              cd ../../../../
              cp -R source/services/data-science-service/rdso/models/ .
              ls -all models/
              ls -al

          inputs:
            - name: source
            - name: data
          outputs:
            - name: models
      - put: models

###################### BUILD SERVICES ############################
  - name: Build UI
    public: true
    serial: true
    plan:
      - get: source
        trigger: true
        params: {depth: 10}
        passed: [Initialize]
      - get: version
        trigger: true
        passed: [Initialize]
      - task: Build Front End
        attempts: 2
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-node10-yarn1-17-3
          run:
            path: sh
            args:
            - -ec
            - |
                echo "begin build front end script"
                cd source/ui/frontend
                echo "building front end"
                npm install --silent
                yarn build
                echo "front end build complete"
                echo "installing sonarqube"
                npm install -g sonarqube-scanner --silent
                sonar-scanner -h
                echo "installing sonarqube"
                sonar-scanner -Dsonar.host.url=http://sonarqube-infra-lb-911331727.us-east-2.elb.amazonaws.com -Dsonar.projectKey=rdso-ui -Dsonar.projectName=rdso-ui -Dsonar.sources=./src
                echo "pushing results to sonarqube complete"

                echo "preparing files for container build"
                cp ./container/Dockerfile ../../../docker/.
                cp ./container/start-nginx.sh ../../../docker/.
                cp -Rf ./container/config ../../../docker/.
                cp -Rf ./build ../../../docker/.
          inputs:
          - name: source
          outputs:
          - name: docker
        on_failure:
          put: slack-notify
          params:
            channel: '#build_notifications'
            text: |
              "Build failed on job 'Build-Project'. Check it out at: 'https://3.226.130.180/teams/main/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME'"
            silent: true

  - name: Execute UI Automated Tests
    public: true
    plan:
      - get: source
        passed:
          - Build server and SonarQube
        trigger: true
      - get: version
        passed:
          - Build server and SonarQube
      - task: Execute Test
        privileged: true
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: bradbytecubed/mdas-pipeline
          run:
            path: entrypoint.sh
            args:
              - bash
              - -exc
              - |
                echo "Noop for now"
          inputs:
            - name: source
          caches:
            - path: maven

  - name: Build server and SonarQube
    serial: true
    public: true
    plan:
      - get: source
        passed:
          - Initialize
        trigger: true
        params:
          depth: 10
      - get: version
        passed:
          - Initialize
        trigger: true
      - task: SonarQube Scan
        attempts: 2
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/openjdk10-maven
          run:
            path: sh
            args:
            - -ec
            - |
              cd source/ui/server
              # must compile first with java10 for sonarqube
              mvn clean install -Djava.version=10 -DskipTests -Dsonar.junit.reportsPath=target/surefire-reports -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn
              mvn sonar:sonar -DskipTests -Dsonar.java.source=10 -B -Dsonar.jacoco.reportPath=target/jacoco.exec -Dsonar.junit.reportsPath=target/surefire-reports -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn -Dsonar.projectKey=rdso-server -Dsonar.projectName=rdso-server -Dsonar.host.url=http://sonarqube-infra-lb-911331727.us-east-2.elb.amazonaws.com -Dsonar.sources=src/main -Dsonar.exclusions=src/main/webapp/WEB-INF/static/build/css/*,src/main/webapp/WEB-INF/static/build/js/* -Dsonar.tests=src/test/java  -Dsonar.java.binaries=./target/classes/
          inputs:
          - name: source
      - task: Build Server
        attempts: 2
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/openjdk12-maven
          run:
            path: sh
            args:
            - -ec
            - |
              cd source/ui/server
              # now build with java 12
              mvn clean install -Djava.version=12 -B -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn ### do tests
          inputs:
          - name: source
          outputs:
          - name: vars
      # on_failure:
      #   put: slack-notify
      #   params:
      #     channel: '#build_notifications'
      #     text: |
      #       "Build failed on job 'Build-Project'. Check it out at: 'https://3.226.130.180/teams/main/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME'"
      #     silent: true

  - name: Execute server Functional Tests
    public: true
    plan:
      - get: source
        passed:
          - Build server and SonarQube
        trigger: true
      - get: version
        passed:
          - Build server and SonarQube
      - task: Execute Test
        privileged: true
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: bradbytecubed/mdas-pipeline
          run:
            path: entrypoint.sh
            args:
              - bash
              - -exc
              - |
                echo "Noop for now"
          inputs:
            - name: source
          caches:
            - path: maven

###################### CONTRACT TESTS ############################
  - name: Execute Data Model Tests
    public: true
    plan:
      - get: source
        trigger: true
        passed: [Initialize]
      - get: models
        trigger: true
        passed: [Train Models]
      - get: version
        trigger: true
        passed: [Initialize]
      - task: Execute Test
        privileged: true
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: python
              tag: 3.7
          inputs:
            - name: source
            - name: version
          run:
            path: /bin/bash
            args:
              - -exc
              - |
                cd source/services/data-science-service
                # pip install --upgrade pip && pip install -r tests_require.txt
                # pip list
                # /usr/local/bin/pytest --junitxml results.xml
                # echo "Push results to sonarqube"
                # wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.0.0.1744-linux.zip
                # unzip -qq sonar-*
                # rm sonar-*.zip
                # mv sonar* sonar-scanner
                # export PROJECT_VERSION=`cat version/number`
                # sonar-scanner/bin/sonar-scanner -h
                # sonar-scanner/bin/sonar-scanner -Dsonar.sources=./rdso -Dsonar.tests=./tests -Dsonar.projectVersion="${PROJECT_VERSION}" -Dsonar.projectKey=rdso-dss -Dsonar.projectName=rdso-dss -Dsonar.host.url=http://sonarqube-infra-lb-907710278.us-east-2.elb.amazonaws.com -Dsonar.python.xunit.reportPath=./results.xml
  - name: Execute server Contract Tests
    public: true
    plan:
      - get: source
        passed:
          - Execute server Functional Tests
        trigger: true
      - get: version
        passed:
          - Execute server Functional Tests
      - task: Execute Test
        privileged: true
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: bradbytecubed/mdas-pipeline
          run:
            path: entrypoint.sh
            args:
              - bash
              - -exc
              - |
                echo "Noop for now"
          inputs:
            - name: source
          caches:
            - path: maven

  ###################### ARTIFACT PUBLISH ############################
  - name: Provision ECR Repositories
    public: true
    serial: true
    plan:
      - get: version
        passed:
          - Execute server Contract Tests
      - get: source
        passed:
          #- Execute main-ds-service Contract Tests
          - Execute server Contract Tests
          - Build UI
          - Execute Data Model Tests
          #- Push Data Model Image
        trigger: true
      - put: terraform
        attempts: 2
        params:
          terraform_source: source/config/ecr-setup
          plan_only: true
          env_name: ecr   #workspace
          env:
            TF_VAR_aws_region: ((bucket_aws_region))
            TF_VAR_aws_account_id: ((aws_account_id))
            TF_VAR_bucket_name: ((tf_backend_bucket))
      - put: terraform
        attempts: 2
        params:
          terraform_source: source/config/ecr-setup
          env_name: ecr
          plan_run: true
          env:
            TF_VAR_aws_region: ((bucket_aws_region))
            TF_VAR_aws_account_id: ((aws_account_id))
            TF_VAR_bucket_name: ((tf_backend_bucket))

  - name: Push UI
    public: true
    plan:
      - get: source
        trigger: true
        passed: [Provision ECR Repositories]
      - get: version
        trigger: true
        passed: [Provision ECR Repositories]
      - task: Build Front End Image
        attempts: 2
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/centos-node10-yarn1-17-3
          run:
            path: sh
            args:
            - -ec
            - |
              echo "begin build front end script"
              cd source/ui/frontend

              echo "building front end"
              npm install  --silent
              yarn build
              echo "front end build complete"

              echo "pushing results to sonarqube"
              echo "pushing results to sonarqube complete"

              echo "preparing files for container build"
              cp ./container/Dockerfile ../../../docker/.
              cp ./container/start-nginx.sh ../../../docker/.
              cp -Rf ./container/config ../../../docker/.
              cp -Rf ./build ../../../docker/.
          inputs:
            - name: source
          outputs:
            - name: docker
      - put: client-docker-image
        params:
          build: docker
          tag_file: version/number

  - name: Push server Image
    public: true
    plan:
      - get: source
        passed:
          - Provision ECR Repositories
        trigger: true
      - get: version
        trigger: true
        passed:
          - Provision ECR Repositories
      - task: Build Server Image
        attempts: 2
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: ugroup/openjdk12-maven
          run:
            path: sh
            args:
            - -ec
            - |
              cd source/ui/server
              mvn clean install -DskipTests -B -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn
              cp Dockerfile ../../../docker
              cp -R target ../../../docker/target
          inputs:
            - name: source
          outputs:
            - name: docker
          caches:
            - path: maven
      - put: server-docker-image
        params:
          build: docker
          tag_file: version/number

  - name: Push Data Model Image
    public: true
    serial: true
    plan:
      - get: source
        trigger: true
        passed: [Provision ECR Repositories]
      - get: version
        trigger: true
        passed: [Provision ECR Repositories]
      - get: models
        trigger: true
        passed: [Execute Data Model Tests]
      - get: data
        trigger: true
      - task: Package API
        attempts: 2
        params:
          AWS_ACCESS_KEY_ID: ((aws_access_key_id))
          AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
          AWS_REGION: ((ecr_aws_region))
        config:
          platform: linux
          image_resource:
            type: docker-image
            source:
              repository: carlomazzaferro/concourse-python-minimal
          run:
            path: sh
            args:
            - -ec
            - |
              cd build
              cp -r ../source/services/data-science-service/rdso/* .
              cp -r ../data/data .
              cp -r ../models/models .
          inputs:
            - name: source
            - name: data
            - name: models
          outputs:
            - name: build
      - put: main-ds-service-docker-image
        params:
          build: build
          tag_file: version/number
###################### DEPLOY SERVICE ############################
  - name: Deploy Services To Dev
    serial: true
    plan:
    - get: source
      passed:
      - Push server Image
      - Push UI
      - Push Data Model Image
      trigger: true
    - get: version
      passed:
      - Push server Image
      - Push UI
      - Push Data Model Image
      trigger: true
    - task: Write Variables and Run TF Deploy
      attempts: 2
      params:
        AWS_ACCESS_KEY_ID: ((aws_access_key_id))
        AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        TF_VAR_access_key: ((aws_secret_access_key))
        TF_VAR_ecr_image_region: ((ecr_aws_region))
        TF_VAR_base_domain: ((base_domain))
        TF_VAR_access_key: ((aws_access_key_id))
        TF_VAR_access_secret: ((aws_secret_access_key))
        TF_VAR_rds_password: ((rds_password))
        TF_VAR_db_pass: ((rds_password))
        TF_VAR_db_user: dbusername1
        TF_VAR_infra_version: useless
        TF_VAR_aws_account_id: ((aws_account_id))
        TF_VAR_jwt_secret: ((jwt_secret))
        TF_VAR_business_user_password: ((business_user_password))
        TF_VAR_business_supervisor_password: ((business_supervisor_password))
        TF_VAR_system_user_password: ((system_user_password))
        TF_VAR_rs_bucket: ((rs_bucket))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ugroup/centos-terraform-aws
        run:
          path: sh
          args:
          - -ec
          - |
              export TF_VAR_images_version=`cat version/number`
              cd source/config/service-setup
              terraform version
              terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=rdso.tfstate"
              terraform workspace new dev || true
              terraform workspace list
              terraform workspace select dev
              terraform init
              terraform refresh
              terraform apply -parallelism=20 --auto-approve
              echo "Waiting for server to come up"
              export SERVER_DNS_NAME=`terraform output server_dns_name`
              export WWW_DNS_NAME=`terraform output www-url`
              cd ../..
              # ./wait-for-status-code-at-url.sh "https://${SERVER_DNS_NAME}/health" 200
              # echo "Server is up!!"
              # export WWW_DNS_NAME=`terraform output www-url`
              # ./wait-for-status-code-at-url.sh "${WWW_DNS_NAME}/" 200
              # echo "UI is up!!"
        inputs:
        - name: source
        - name: version
        outputs:
        - name: vars

  - name: Deploy Services To Test
    serial: true
    plan:
    - get: source
      passed:
      - Deploy Services To Dev
      trigger: true
    - get: version
      passed:
      - Deploy Services To Dev
      trigger: true
    - task: Write Variables and Run TF Deploy
      attempts: 2
      params:
        AWS_ACCESS_KEY_ID: ((aws_access_key_id))
        AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        TF_VAR_access_key: ((aws_secret_access_key))
        TF_VAR_ecr_image_region: ((ecr_aws_region))
        TF_VAR_base_domain: ((base_domain))
        TF_VAR_access_key: ((aws_access_key_id))
        TF_VAR_access_secret: ((aws_secret_access_key))
        TF_VAR_rds_password: ((rds_password))
        TF_VAR_db_pass: ((rds_password))
        TF_VAR_db_user: dbusername1
        TF_VAR_infra_version: useless
        TF_VAR_aws_account_id: ((aws_account_id))
        TF_VAR_jwt_secret: ((jwt_secret))
        TF_VAR_business_user_password: ((business_user_password))
        TF_VAR_business_supervisor_password: ((business_supervisor_password))
        TF_VAR_system_user_password: ((system_user_password))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ugroup/centos-terraform-aws
        run:
          path: sh
          args:
          - -ec
          - |
            export TF_VAR_images_version=`cat version/number`

            cd source/config/service-setup
            terraform version
            terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=rdso.tfstate"
            # Always try to create the workspace, ignore non-zero exit code if it already exists
            terraform workspace new test || true
            terraform workspace list
            terraform workspace select test
            terraform init
            terraform refresh
            terraform apply -parallelism=20 --auto-approve

            echo "Waiting for server to come up"
            export SERVER_DNS_NAME=`terraform output server_dns_name`
            export WWW_DNS_NAME=`terraform output www-url`
            cd ../..
            # ./wait-for-status-code-at-url.sh "${SERVER_DNS_NAME}/health" 200
            # echo "Server is up!!"
            # export WWW_DNS_NAME=`terraform output www-url`
            # ./wait-for-status-code-at-url.sh "${WWW_DNS_NAME}/" 200
            # echo "UI is up!!"
        inputs:
        - name: source
        - name: version
        outputs:
        - name: vars

  - name: Deploy Services To Production
    serial: true
    plan:
    - get: source
      passed:
      - Deploy Services To Test
      #trigger: true
    - get: version
      passed:
      - Deploy Services To Test
      #trigger: true
    - task: Write Variables and Run TF Deploy
      attempts: 2
      params:
        AWS_ACCESS_KEY_ID: ((aws_access_key_id))
        AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        TF_VAR_access_key: ((aws_secret_access_key))
        TF_VAR_ecr_image_region: ((ecr_aws_region))
        TF_VAR_base_domain: ((base_domain))
        TF_VAR_access_key: ((aws_access_key_id))
        TF_VAR_access_secret: ((aws_secret_access_key))
        TF_VAR_rds_password: ((rds_password))
        TF_VAR_db_pass: ((rds_password))
        TF_VAR_db_user: dbusername1
        TF_VAR_infra_version: useless
        TF_VAR_aws_account_id: ((aws_account_id))
        TF_VAR_jwt_secret: ((jwt_secret))
        TF_VAR_business_user_password: ((business_user_password))
        TF_VAR_business_supervisor_password: ((business_supervisor_password))
        TF_VAR_system_user_password: ((system_user_password))
        TF_VAR_rs_bucket: ((rs_bucket))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ugroup/centos-terraform-aws
        run:
          path: sh
          args:
          - -ec
          - |
            export TF_VAR_images_version=`cat version/number`

            cd source/config/service-setup
            terraform version
            terraform init -backend-config "bucket=((tf_backend_bucket))" -backend-config "region=((bucket_aws_region))" -backend-config "key=rdso.tfstate"
            # Always try to create the workspace, ignore non-zero exit code if it already exists
            terraform workspace new prod || true
            terraform workspace list
            terraform workspace select prod
            terraform init
            terraform refresh
            terraform apply -parallelism=20 --auto-approve
            
            echo "wait for HSM to be up"
            #while [ -z "$HSM_SERVER_IP" ]; do terraform refresh; export HSM_SERVER_IP=`terraform output hsm_ec2_ip`; done
            
            #./wait-for-status-code-at-url.sh "${HSM_SERVER_IP}:8080/hello" 200

            echo "Waiting for server to come up"
            export SERVER_DNS_NAME=`terraform output server_dns_name`
            export WWW_DNS_NAME=`terraform output www-url`
            cd ../..
            # ./wait-for-status-code-at-url.sh "${SERVER_DNS_NAME}/health" 200
            # echo "Server is up!!"
            # export WWW_DNS_NAME=`terraform output www-url`
            # ./wait-for-status-code-at-url.sh "${WWW_DNS_NAME}/" 200
            # echo "UI is up!!"
        inputs:
        - name: source
        - name: version
        outputs:
        - name: vars

  - name: OWASP Prod Security Scan
    serial: false
    plan:
    - get: version
      trigger: true
      passed:
        - Deploy Services To Dev
      # passed:
      #   - Deploy Services To Productionuction
    - task: get-lb
      attempts: 2
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: mesosphere/aws-cli
        outputs:
          - name: lb-name
        run:
          path: sh
          args:
          - -exc
          - |
            export WWW_LB_TEST=$(AWS_REGION=((dev_aws_region)) AWS_ACCESS_KEY_ID=((aws_access_key_id)) AWS_SECRET_ACCESS_KEY=((aws_secret_access_key)) aws elbv2 describe-load-balancers --names "www-lb"  --query 'LoadBalancers[].DNSName' --output text)
            echo "our www URL $WWW_LB_TEST"
            echo "$WWW_LB_TEST" > lb-name/name.txt
    - task: Execute scan
      privileged: true
      timeout: 5m
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: owasp/zap2docker-weekly
        outputs:
            - name: scan
        inputs:
          - name: lb-name
        run:
          path: /bin/bash
          args:
          - -c
          - |
            echo "starting scan"
            echo "lb name"
            export WWW_LB_TEST=`cat lb-name/name.txt`
            apt-get -y update
            apt-get -y install procps
            cd  #NEED THIS
            #whoami; pwd #/home/zap
            mkdir -p /zap/wrk
            touch /zap/wrk/report_md
            /zap/zap-baseline.py -t https://${WWW_LB_TEST} -m 3 -i
            echo "scan successful"
            ps -ef
            ps -ef | grep "zap" |  grep -v grep| awk '{print $2}'|xargs kill
            echo "done"
            exit 0
  - name: pa11y-accessibility-scan
    plan:
    - get: version
    - get: source
      trigger: true
      passed:
        - Deploy Services To Dev
    - task: get-lb
      attempts: 5
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: mesosphere/aws-cli
        outputs:
          - name: lb-name
        run:
          path: sh
          args:
          - -exc
          - |
              export REGION=us-east-1 
              export AWS_DEFAULT_REGION=us-east-1 
              export AWS_ACCESS_KEY_ID=((aws_access_key_id)) 
              export AWS_SECRET_ACCESS_KEY=((aws_secret_access_key)) 
              export WWW_LB_TEST=$(aws elbv2 describe-load-balancers --names 'www-lb'  --query 'LoadBalancers[].DNSName' --output text)
              echo "our www URL $WWW_LB_TEST"
              echo "$WWW_LB_TEST" > lb-name/name.txt
    - task: run-pa11y
      attempts: 5
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: node
        inputs:
          - name: lb-name
        run:
          path: sh
          args:
          - -exc
          - |
            echo "lb name"
            export WWW_LB_TEST=`cat lb-name/name.txt`
            mkdir myproj2
            cd myproj2
            apt-get -y -qq update
            apt-get -o=Dpkg::Use-Pty=0 -y -qq install gconf-service libasound2 libatk1.0-0 libatk-bridge2.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 ca-certificates fonts-liberation libappindicator1 libnss3 lsb-release xdg-utils wget
            # run pa11y headless
            npm install pa11y-ci --unsafe-perm=true --allow-root  --silent
            #npm install pa11y-reporter-ci
            cat <<EOF >> config.json
            { "defaults": { "chromeLaunchConfig": { "args": ["--no-sandbox"], "ignoreHTTPSErrors": "false", "executablePath": "node_modules/puppeteer/.local-chromium/linux-674921/chrome-linux/chrome" }, "timeout": 20000, "wait": 2000, "ignore": [] }, "urls": [ "https://${WWW_LB_TEST}" ] }
            EOF
            # finally scan
            cat config.json
            node node_modules/pa11y-ci/bin/pa11y-ci.js --json -c config.json
            echo "*******ACCESSIBILITY TESTING RESULTS******"
            cat summary.txt
