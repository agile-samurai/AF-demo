{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U.Group RDSO AI/ML Notebook\n",
    "\n",
    "This notebook demonstrates the AI and ML features implemented in the U.Group RDSO submission website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Pipeline\n",
    "The general outline of our data processing pipeline is as follows:\n",
    "\n",
    "* Scrape movie data from various freely available sources (e.g. OMDB, MovieTweetings)\n",
    "* Clean and parse the data\n",
    "* Join the various data sources - most include the IMDB ID, which can be used as a unique key\n",
    "* Parse the data fields into standardized formats across the application\n",
    "* Join together multiple descriptive text fields into a single `description` field\n",
    "* Clean, preprocess, and tokenize the `description` field in preparation for vectorization\n",
    "\n",
    "The output of this processing is the raw scraped data in the `data/` subfolder, and a pickle file containing a `pandas Dataframe` of the processed data, ready for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdso import movies, vectorize, plot\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17351 movies\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path(\".\").resolve()\n",
    "data_dir = cwd / \"data\"\n",
    "movies_df_file = data_dir / \"movies_df.pkl\"\n",
    "movies_df = pd.read_pickle(str(movies_df_file))\n",
    "print(f\"Loaded {len(movies_df)} movies\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science AI/ML Pipeline\n",
    "* Train a Doc2Vec model on our cleaned & tokenized movie descriptions\n",
    "* Use movie genres from OMDB as categories to create clusters\n",
    "* Find the centroid of each cluster\n",
    "* Measure the mean and standard deviation of movie distances from center within each cluster, and record this as our metric for model performance. A higher-performing model will result in tighter clusters, with a smaller mean and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec has a great feature that allows you to tag each document prior to training, and that tag will be retained with the created document vectors so that you can look up a document by tag. We will create a tagged corpus using the IMDB IDs that are common among our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_labels = list(movies_df[\"film_id\"])\n",
    "movie_tokens = movies_df[\"movie_tokens\"].tolist()\n",
    "tagged_corpus = vectorize.TaggedLineDocument(movie_tokens, movies_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the Doc2Vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = vectorize.train_doc2vec(tagged_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a collection of tagged document vectors. We can use these to go through each of the genres in our `movies_df` data and find the centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentary: mean 0.8740, standard deviation 0.3419\n",
      "Comedy: mean 0.8888, standard deviation 0.2797\n",
      "Action: mean 0.8590, standard deviation 0.2594\n",
      "Animation: mean 0.8356, standard deviation 0.2708\n",
      "Crime: mean 0.8589, standard deviation 0.2826\n",
      "Drama: mean 0.8755, standard deviation 0.2602\n",
      "Short: mean 0.8682, standard deviation 0.3933\n",
      "Horror: mean 0.8574, standard deviation 0.3041\n",
      "Mystery: mean 0.9434, standard deviation 0.4701\n",
      "Biography: mean 0.8938, standard deviation 0.2857\n",
      "Thriller: mean 0.8943, standard deviation 0.2824\n",
      "Fantasy: mean 0.9223, standard deviation 0.5597\n",
      "Adventure: mean 0.8591, standard deviation 0.2941\n",
      "Sci-Fi: mean 0.7786, standard deviation 0.2226\n",
      "Family: mean 0.8521, standard deviation 0.3740\n",
      "Adult: mean 0.0000, standard deviation 0.0000\n",
      "Romance: mean 0.8767, standard deviation 0.2822\n",
      "News: mean 0.8314, standard deviation 0.2249\n",
      "Musical: mean 0.9085, standard deviation 0.1229\n",
      "History: mean 0.7476, standard deviation 0.1873\n",
      "Music: mean 0.8547, standard deviation 0.2092\n",
      "War: mean 0.0000, standard deviation 0.0000\n",
      "Sport: mean 0.5878, standard deviation 0.1499\n",
      "Western: mean 0.6553, standard deviation 0.0928\n",
      "Reality-TV: mean 0.0000, standard deviation 0.0000\n"
     ]
    }
   ],
   "source": [
    "genre_metrics, genre_centroids = vectorize.get_genre_distance_metrics(d2v_model, movies_df)\n",
    "for genre in genre_metrics.items():\n",
    "    print(f'{genre[0]}: mean {genre[1][\"mean\"]:0.4f}, standard deviation {genre[1][\"stdev\"]:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a text description of a movie that is not in our dataset, we can preprocess, clean, and tokenize the text, then pass the tokens to the Doc2Vec model to find the genre it would fit best in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Hard movie tokens: ['police', 'hands', 'escape', 'nakatomi', 'gruber', 'goes'], ...\n"
     ]
    }
   ],
   "source": [
    "die_hard_imdbID = \"tt0095016\"\n",
    "die_hard_description = \"NYPD cop John McClane goes on a Christmas vacation to visit his wife Holly in Los Angeles where she works for the Nakatomi Corporation. While they are at the Nakatomi headquarters for a Christmas party, a group of robbers led by Hans Gruber take control of the building and hold everyone hostage, with the exception of John, while they plan to perform a lucrative heist. Unable to escape and with no immediate police response, John is forced to take matters into his own hands.\"\n",
    "die_hard_tokens = movies.nlp_clean(die_hard_description)\n",
    "print(f\"Die Hard movie tokens: {die_hard_tokens[:6]}, ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reality-TV 4.6758966\n"
     ]
    }
   ],
   "source": [
    "die_hard_vectors = d2v_model.infer_vector(die_hard_tokens)\n",
    "genre_distances = {}\n",
    "min_distance = 10\n",
    "min_genre = None\n",
    "for genre in genre_centroids.items():\n",
    "    genre_distance = np.linalg.norm(die_hard_vectors - genre[1])\n",
    "    genre_distances[genre[0]] = genre_distance\n",
    "    if genre_distance < min_distance:\n",
    "        min_distance = genre_distance\n",
    "        min_genre = genre[0]\n",
    "print(min_genre, min_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
